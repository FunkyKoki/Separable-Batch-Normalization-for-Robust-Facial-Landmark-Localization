# Separable-Batch-Normalization-for-Robust-Facial-Landmark-Localization

## Introduction

---

Separable Batch Normalization (abbreviated as *SepBN*) is a novel variant of the original Batch Normalization (BN). Different from the classical BN module, the proposed SepBN module learns multiple sets of mapping parameters to adaptively scale and shift the normalized feature maps via a feed-forward attention mechanism. Channels of the input tensor are divided into several groups and different mapping parameter combinations are calculated for each group according to the attention weights to further improve the parameter utilization. We apply the proposed SepBN on face alignment task and look forward to seeing its application in more machine learning tasks. 

![](https://raw.githubusercontent.com/FunkyKoki/PhotoCloud/master/20211019135212.png)

## Requirements

```tex
torch==1.7.0
numpy==1.19.2
opencv_python==4.4.0.46
```

## Data Preparation

---

To speed up the data loading, we pre-process the original WFLW dataset by cropping a face patch in the size of **256\*256** around the face bounding box. The processing flow can be found in `/dataset/createWFLW256.py`.

## Model

---

| Model               | Input size  | Output landmark number | Computational complexity | Number of parameters | Error Rate (%) |
| ------------------- | ----------- | ---------------------- | ------------------------ | -------------------- | -------------- |
| Vanilla CNN         | 128\*128\*3 | 98 (**WFLW** protocol) | 1.56 GMac                | 42.33 M              | 5.70           |
| Vanilla CNN (SepBN) | 128\*128\*3 | 98 (**WFLW** protocol) | 1.58 GMac                | 42.91 M              | 5.48           |

## Test

---

You can evaluate the performance of the model simply by

```bash
python test.py
```

## Train

---

You can train the Vanilla CNN network by

```bash
python trainBaseline.py
```

You can train the Vanilla CNN equipped with SepBN by

```bash
trainBaselineSepDyBN.py
```

## Visualization

Visualization of the 5 SepBN modules with K = 3 sets of mapping parameters (left: scale parameters; right: shift parameters) applied in Vanilla CNN trained on WFLW. 

![](https://raw.githubusercontent.com/FunkyKoki/PhotoCloud/master/20211019143138.png)

Visualization of the attention weights generated by the 5 SepBN modules (column by column, 5 columns in total) in the Vanilla CNN network trained on WFLW. 

![](https://raw.githubusercontent.com/FunkyKoki/PhotoCloud/master/20211019143423.png)

## License

---

This repository is released under the MIT LICENSE.

## Citation

---

TBD

